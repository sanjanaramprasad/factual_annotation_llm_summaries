{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb11c79-3b00-43f1-9710-e331018ec8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import string \n",
    "import re\n",
    "\n",
    "import json \n",
    "\n",
    "import pandas as pd \n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6609027b-fc87-4543-a98d-2a9df7c71545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def connect_to_db(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    return conn, c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8eb844d-57ed-43a1-bdb0-3c089c31cf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_path = '/home/ramprasad.sa'\n",
    "db_path = f'{parent_path}/human_annotations_factuality/billsum/set1/annotated/billsum_summaries_set1_final.db'\n",
    "conn, c = connect_to_db(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50f11a88-b981-4e52-83a7-8d5d5c7614df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qualified_annotators_billsum = ['ann_krcnbm', 'ann_hguilf']\n",
    "qualified_annotators_news = ['ann_japq', 'ann_tpfo']\n",
    "qualified_annotators_pubmed = ['ann_jclvzw', 'ann_eftpco']\n",
    "df_annotations = pd.read_sql('SELECT * from label', conn)\n",
    "# df_annotations = df_annotations[df_annotations['user_id'].isin(qualified_annotators_billsum)]\n",
    "\n",
    "# df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3776fb78-844b-46e9-8c3d-f34e956bf2af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ann_krcnbm', 'sanjana', 'ann_hguilf', 'ann_ckorrj', 'ann_dnifqq']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df_annotations['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b2b0f61-96b8-4d2a-bac7-2f5432e5d00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def remove_duplicates(df, qualified_annotators):\n",
    "    processed_rows = []\n",
    "    \n",
    "    for annotator in qualified_annotators:\n",
    "        \n",
    "        df_qualified_annotators = df[df['user_id'] == annotator]\n",
    "        for each_id in list(set(df_qualified_annotators['summary_uuid'].values)):\n",
    "            df_uid = df_qualified_annotators[df_qualified_annotators['summary_uuid'] == each_id]\n",
    "            if len(df_uid) == 1:\n",
    "                row_append = df_uid.iloc[[0]]\n",
    "            else:\n",
    "                row_append = df_uid.iloc[[-1]]\n",
    "            processed_rows.append(row_append)\n",
    "            \n",
    "    df_processed = pd.concat(processed_rows)\n",
    "    return df_processed\n",
    "                \n",
    "        \n",
    "\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aec465b4-8a81-4328-95e2-e941e0abff38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>summary_uuid</th>\n",
       "      <th>summ_id</th>\n",
       "      <th>system_id</th>\n",
       "      <th>label_type</th>\n",
       "      <th>summary</th>\n",
       "      <th>nonfactual_sentences</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>ann_krcnbm</td>\n",
       "      <td>4f011fe6-8caf-4693-a64c-9caca556b5cc_gpt3_gen</td>\n",
       "      <td>billsum_generic</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>non_factual</td>\n",
       "      <td>The Trade Dress Protection Act is a new law th...</td>\n",
       "      <td>The act also amends the Trademark Act of 1946,...</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>ann_krcnbm</td>\n",
       "      <td>b9eab77b-1667-472a-a44a-7bf03ae272cd_gpt3_gen</td>\n",
       "      <td>billsum_generic</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>non_factual</td>\n",
       "      <td>The Tobacco Advertising and Promotion Studies ...</td>\n",
       "      <td>The act is based on Congress' findings that to...</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>ann_krcnbm</td>\n",
       "      <td>6031839a-de71-4eed-8a08-1d7218747543_flant5_gen</td>\n",
       "      <td>billsum_generic</td>\n",
       "      <td>flant5</td>\n",
       "      <td>factual</td>\n",
       "      <td>To amend the Internal Revenue Code of 1986 to ...</td>\n",
       "      <td></td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>ann_krcnbm</td>\n",
       "      <td>be653902-8770-480c-a0d9-b9f70081157c_flant5_gen</td>\n",
       "      <td>billsum_generic</td>\n",
       "      <td>flant5</td>\n",
       "      <td>factual</td>\n",
       "      <td>To amend the Internal Revenue Code of 1986 to ...</td>\n",
       "      <td></td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111</td>\n",
       "      <td>ann_krcnbm</td>\n",
       "      <td>be9b5d8c-35fd-4b30-9f87-02f759883304_flant5_gen</td>\n",
       "      <td>billsum_generic</td>\n",
       "      <td>flant5</td>\n",
       "      <td>non_factual</td>\n",
       "      <td>A bill to reduce the deficit by a total of $70...</td>\n",
       "      <td>A bill to reduce the deficit by a total of $70...</td>\n",
       "      <td>67 with respect to deficit reduction are \\r\\na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uuid     user_id                                     summary_uuid   \n",
       "66     67  ann_krcnbm    4f011fe6-8caf-4693-a64c-9caca556b5cc_gpt3_gen  \\\n",
       "107   108  ann_krcnbm    b9eab77b-1667-472a-a44a-7bf03ae272cd_gpt3_gen   \n",
       "71     72  ann_krcnbm  6031839a-de71-4eed-8a08-1d7218747543_flant5_gen   \n",
       "108   109  ann_krcnbm  be653902-8770-480c-a0d9-b9f70081157c_flant5_gen   \n",
       "110   111  ann_krcnbm  be9b5d8c-35fd-4b30-9f87-02f759883304_flant5_gen   \n",
       "\n",
       "             summ_id system_id   label_type   \n",
       "66   billsum_generic      gpt3  non_factual  \\\n",
       "107  billsum_generic      gpt3  non_factual   \n",
       "71   billsum_generic    flant5      factual   \n",
       "108  billsum_generic    flant5      factual   \n",
       "110  billsum_generic    flant5  non_factual   \n",
       "\n",
       "                                               summary   \n",
       "66   The Trade Dress Protection Act is a new law th...  \\\n",
       "107  The Tobacco Advertising and Promotion Studies ...   \n",
       "71   To amend the Internal Revenue Code of 1986 to ...   \n",
       "108  To amend the Internal Revenue Code of 1986 to ...   \n",
       "110  A bill to reduce the deficit by a total of $70...   \n",
       "\n",
       "                                  nonfactual_sentences   \n",
       "66   The act also amends the Trademark Act of 1946,...  \\\n",
       "107  The act is based on Congress' findings that to...   \n",
       "71                                                       \n",
       "108                                                      \n",
       "110  A bill to reduce the deficit by a total of $70...   \n",
       "\n",
       "                                               article  \n",
       "66   SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...  \n",
       "107  SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...  \n",
       "71   SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...  \n",
       "108  SECTION 1. SHORT TITLE.\\r\\n\\r\\n    This Act ma...  \n",
       "110  67 with respect to deficit reduction are \\r\\na...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = remove_duplicates(df_annotations, qualified_annotators_billsum)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b3baf5d-11ed-4738-b2f5-4e9a724ea6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6507936507936508"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flan = df[df['system_id'] == 'gpt3']\n",
    "df_flan = df_flan[df_flan['label_type'] == 'non_factual']\n",
    "nonfact_sents = \n",
    "len(set(df_flan['summary_uuid']))/len(df_flan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e55db073-2cd2-4cc5-ac14-969cfb6867f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df['article'].values[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a67e09d-3e62-4033-a306-e30ccc975773",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 1.0\n",
      " Aggreement (labels only) :  0.82\n",
      " Aggreement (labels and sentences) :  0.82\n"
     ]
    }
   ],
   "source": [
    "''' Annotator agreement \n",
    "Same labels \n",
    "Same labels and sentences \n",
    "'''\n",
    "user_ids = list(set(df['user_id'].values))\n",
    "df_ann1 = df[df['user_id'] == user_ids[0]]\n",
    "df_ann2 = df[df['user_id'] == user_ids[1]]\n",
    "\n",
    "df_ann1_overlap = df_ann1[df_ann1['summary_uuid'].isin(df_ann2['summary_uuid'].values)]\n",
    "df_ann2_overlap = df_ann2[df_ann2['summary_uuid'].isin(df_ann1['summary_uuid'].values)]\n",
    "df_ann1_overlap = df_ann1_overlap.sort_values(['summary_uuid'])\n",
    "df_ann2_overlap = df_ann2_overlap.sort_values(['summary_uuid'])\n",
    "assert(list(df_ann1_overlap['summary_uuid'].values) == list(df_ann2_overlap['summary_uuid'].values))\n",
    "\n",
    "print('Progress', len(df_ann2_overlap)/100)\n",
    "label_aggr_condition = df_ann2_overlap['label_type'].values == df_ann1_overlap['label_type'].values\n",
    "sentence_aggr_condition = df_ann2_overlap['nonfactual_sentences'].values == df_ann1_overlap['nonfactual_sentences'].values\n",
    "\n",
    "print(' Aggreement (labels only) : ', \\\n",
    "      len(df_ann2_overlap[label_aggr_condition])/len(df_ann2_overlap))\n",
    "print(' Aggreement (labels and sentences) : ', \n",
    "     len(df_ann2_overlap[(label_aggr_condition) & (sentence_aggr_condition) ])/len(df_ann2_overlap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0afa243a-26a1-47fd-b9c8-dfafe55cf47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_ann1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76079838-d1ce-48f0-81af-515de594b07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (270690715.py, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 48\u001b[0;36m\u001b[0m\n\u001b[0;31m    sentbased_score = np.mean(annotated_sentences)/\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Error Statistics:\n",
    "Labeled as nonfactual --> absolute score (1/0)\n",
    "Labeld as nonfactual --> get overlapping sentences --> get score of #nonfact sentences/len(summary sents)\n",
    "Record relative scores and make a new df to get correlation\n",
    "'''\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_error_stats(datatypes, qualified_annotators, agreement):\n",
    "    non_factual_dict = {\n",
    "                    'article': [],\n",
    "                    'summary': [],\n",
    "                    'model' : [],\n",
    "                    'data': [],\n",
    "                    'non_factual_sents': [], \n",
    "                    'label_type': [], \\\n",
    "                  'num_summary_sents' : []}\n",
    "    for datatype in datatypes:\n",
    "        df_data = df[df['summ_id'] == f'{datatype}_generic']\n",
    "        \n",
    "        for model in ['flant5', 'gpt3']:\n",
    "            df_model = df_data[df_data['system_id'] == model]\n",
    "\n",
    "            for unique_ids in list(set(df_model['summary_uuid'])):\n",
    "                \n",
    "                df_uuid = df_model[df_model['summary_uuid'] == unique_ids]\n",
    "                # print(df_uuid)\n",
    "                article = df_uuid['article'].values[0]\n",
    "                user_ids_uuid =   set(list(df_uuid['user_id'].values))\n",
    "                summary = df_uuid['summary'].values[0]\n",
    "                summ_sents =  list(nlp(summary).sents)\n",
    "                sentences_ann = list(df_uuid['nonfactual_sentences'].values)\n",
    "                    \n",
    "                annotated_sentences = []\n",
    "                for each_sent in sentences_ann:\n",
    "                    score = 0\n",
    "                    if each_sent:\n",
    "                        score = len(each_sent.split('<new_annotation>'))\n",
    "                    annotated_sentences.append(score/len(summ_sents))\n",
    "                \n",
    "                sentbased_score = np.mean(annotated_sentences)\n",
    "                # print(sentbased_score, annotated_sentences)\n",
    "                non_factual_dict['article'] += [article]\n",
    "                non_factual_dict['summary'] += [summary]\n",
    "                non_factual_dict['model'] += [model]\n",
    "                non_factual_dict['data'] += [datatype]\n",
    "                non_factual_dict['non_factual_sents'] += [sentbased_score]\n",
    "                label_type = 1 if sentbased_score >0 else 0\n",
    "                non_factual_dict['label_type'] += [label_type]\n",
    "                non_factual_dict['num_summary_sents'] += [len(summ_sents)]\n",
    "                            \n",
    "    return pd.DataFrame(non_factual_dict)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95d12521-4512-46a2-a361-caa36801b30d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>non_factual_sents</th>\n",
       "      <th>label_type</th>\n",
       "      <th>num_summary_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an important goal of microarray studies with ...</td>\n",
       "      <td>a comparison of the performance of classificat...</td>\n",
       "      <td>flant5</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>massively parallel sequencing technology can ...</td>\n",
       "      <td>a method for detecting copy-number variants fr...</td>\n",
       "      <td>flant5</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mitochondrial genomes are physically separate...</td>\n",
       "      <td>This article describes the complete mitochondr...</td>\n",
       "      <td>flant5</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it is well known that the teflon event involv...</td>\n",
       "      <td>pfoa is a persistent and non-biodegradable che...</td>\n",
       "      <td>flant5</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a great deal of effort and expense are being ...</td>\n",
       "      <td>a java based linkage disequilibrium plotter</td>\n",
       "      <td>flant5</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>feline herpesvirus, an alphaherpesvirus, is o...</td>\n",
       "      <td>Feline herpesvirus is a common virus in cats t...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>genome sequencing projects are generating mas...</td>\n",
       "      <td>This article discusses the challenges in annot...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>one of the critical considerations in cereal ...</td>\n",
       "      <td>The article discusses the importance of select...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>the ca2+-dependent activator protein for secr...</td>\n",
       "      <td>The article discusses the Ca2+-dependent activ...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>recombinant adenoviral vectors are highly eff...</td>\n",
       "      <td>The article describes a simplified and easy me...</td>\n",
       "      <td>gpt3</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article   \n",
       "0    an important goal of microarray studies with ...  \\\n",
       "1    massively parallel sequencing technology can ...   \n",
       "2    mitochondrial genomes are physically separate...   \n",
       "3    it is well known that the teflon event involv...   \n",
       "4    a great deal of effort and expense are being ...   \n",
       "..                                                ...   \n",
       "95   feline herpesvirus, an alphaherpesvirus, is o...   \n",
       "96   genome sequencing projects are generating mas...   \n",
       "97   one of the critical considerations in cereal ...   \n",
       "98   the ca2+-dependent activator protein for secr...   \n",
       "99   recombinant adenoviral vectors are highly eff...   \n",
       "\n",
       "                                              summary   model    data   \n",
       "0   a comparison of the performance of classificat...  flant5  pubmed  \\\n",
       "1   a method for detecting copy-number variants fr...  flant5  pubmed   \n",
       "2   This article describes the complete mitochondr...  flant5  pubmed   \n",
       "3   pfoa is a persistent and non-biodegradable che...  flant5  pubmed   \n",
       "4         a java based linkage disequilibrium plotter  flant5  pubmed   \n",
       "..                                                ...     ...     ...   \n",
       "95  Feline herpesvirus is a common virus in cats t...    gpt3  pubmed   \n",
       "96  This article discusses the challenges in annot...    gpt3  pubmed   \n",
       "97  The article discusses the importance of select...    gpt3  pubmed   \n",
       "98  The article discusses the Ca2+-dependent activ...    gpt3  pubmed   \n",
       "99  The article describes a simplified and easy me...    gpt3  pubmed   \n",
       "\n",
       "    non_factual_sents  label_type  num_summary_sents  \n",
       "0            0.000000           0                  1  \n",
       "1            0.500000           1                  1  \n",
       "2            0.000000           0                  1  \n",
       "3            0.411765           1                 17  \n",
       "4            0.000000           0                  1  \n",
       "..                ...         ...                ...  \n",
       "95           0.000000           0                  6  \n",
       "96           0.000000           0                  4  \n",
       "97           0.000000           0                  4  \n",
       "98           0.100000           1                  5  \n",
       "99           0.000000           0                  4  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatypes = ['xsum', 'cnndm']\n",
    "# datatypes = ['billsum']\n",
    "datatypes = ['pubmed']\n",
    "qualified_annotators = qualified_annotators_pubmed\n",
    "agreement = 2\n",
    "df_error = make_error_stats(datatypes, qualified_annotators, agreement)\n",
    "# df_error.to_csv(f'error_scores_{\"_\".join(datatypes)}.csv')\n",
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4db3893e-5204-43bd-930e-556c2f2f1c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pubmed\n",
      "Model gpt3\n",
      "Avg num sentences 5.46\n",
      "0.028070818070818074\n",
      "Model flant5\n",
      "Avg num sentences 2.28\n",
      "0.06115196078431372\n"
     ]
    }
   ],
   "source": [
    "####### News\n",
    "for data in list(set(df_error['data'])):\n",
    "    print('Data' , data)\n",
    "    for model in list(set(df_error['model'])):\n",
    "        print('Model', model)\n",
    "        df_error_dm = df_error[(df_error['data'] == data) & (df_error['model'] == model)]\n",
    "        num_non_factual = list(df_error_dm['label_type'].values)\n",
    "        num_non_factual_sents = list(df_error_dm['non_factual_sents'].values)\n",
    "        num_summ_sents = list(df_error_dm['num_summary_sents'].values)\n",
    "        if len(df_error_dm):\n",
    "            print('Avg num sentences', np.mean(num_summ_sents))\n",
    "            # print(sum(num_non_factual)/len(df_error_dm))\n",
    "            print(np.mean(num_non_factual_sents))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "843d82b2-2d70-4a6e-a796-808c08fed4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gpt3\n",
      "Avg num sentences 4.84\n",
      "0.2008095238095238\n",
      "Model flant5\n",
      "Avg num sentences 1.0\n",
      "0.23\n"
     ]
    }
   ],
   "source": [
    "for model in list(set(df_error['model'])):\n",
    "        print('Model', model)\n",
    "        df_error_dm = df_error[(df_error['model'] == model)]\n",
    "        num_non_factual = list(df_error_dm['label_type'].values)\n",
    "        num_non_factual_sents = list(df_error_dm['non_factual_sents'].values)\n",
    "        num_summ_sents = list(df_error_dm['num_summary_sents'].values)\n",
    "        if len(df_error_dm):\n",
    "            print('Avg num sentences', np.mean(num_summ_sents))\n",
    "            # print(sum(num_non_factual)/len(df_error_dm))\n",
    "            print(np.mean(num_non_factual_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca6c091c-ce37-4438-b2a9-40517d6ff819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>non_factual_sents</th>\n",
       "      <th>label_type</th>\n",
       "      <th>num_summary_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, data, non_factual_sents, label_type, num_summary_sents]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "401bc969-76c8-4408-a180-1e0a8c86b805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCorrelation of summary length with factuality score\\n\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Correlation of summary length with factuality score\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e2a0a80-1a6d-42da-b954-9be8021e9f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_error_stats(df, data, qualified_annotators, agreement = 2):\n",
    "    print('Fraction of factual errors')\n",
    "    df_data = df[df['summ_id'] == f'{data}_generic']\n",
    "    print(f'{data}_generic', len(df_data))\n",
    "    for model in ['flant5', 'gpt3']:\n",
    "        df_model = df_data[df_data['system_id'] == model]\n",
    "        print(len(df_model))\n",
    "        non_factual_num = []\n",
    "        filtered_ids = []\n",
    "        for unique_ids in list(set(df_model['summary_uuid'])):\n",
    "            df_uuid = df_model[df_model['summary_uuid'] == unique_ids]\n",
    "            user_ids_uuid =   set(list(df_uuid['user_id'].values))\n",
    "            if len(user_ids_uuid) >= agreement:\n",
    "                filtered_ids.append(unique_ids)\n",
    "                label_types = list(df_uuid['label_type'].values)\n",
    "\n",
    "                if len(set(label_types)) == 1:\n",
    "                    if label_types[0] == 'non_factual':\n",
    "                        non_factual_num.append(unique_ids)\n",
    "        print(model, len(non_factual_num)/len(filtered_ids), len(filtered_ids))\n",
    "            \n",
    "    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c4a4f3f0-8050-4644-b7fd-e8e37c22c817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of factual errors\n",
      "xsum_generic 98\n",
      "49\n",
      "flant5 0.5 24\n",
      "49\n",
      "gpt3 0.4583333333333333 24\n",
      "Fraction of factual errors\n",
      "cnndm_generic 45\n",
      "22\n",
      "flant5 0.0 7\n",
      "23\n",
      "gpt3 0.2857142857142857 7\n"
     ]
    }
   ],
   "source": [
    "get_error_stats(df, 'xsum', qualified_annotators_news)\n",
    "get_error_stats(df, 'cnndm', qualified_annotators_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "648bbbe4-e9e9-4538-8748-947bb3956b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_dicts(df):\n",
    "    summary_annotations = {}\n",
    "    label_annotations = {}\n",
    "    sent_annotations = {}\n",
    "    all_summ_uuids = sorted(list(set(df['summary_uuid'].values)), key = len)\n",
    "\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        summ_uuid = row['summary_uuid']\n",
    "        label_type = row['label_type']\n",
    "        nonfact_sents = row['nonfactual_sentences']\n",
    "\n",
    "        if summ_uuid not in summary_annotations:\n",
    "            summary_annotations[summ_uuid] = {}\n",
    "\n",
    "        if user_id not in label_annotations:\n",
    "            label_annotations[user_id] = {'factual': [], 'non_factual': []}\n",
    "            sent_annotations[user_id] = [''] * len(all_summ_uuids)\n",
    "\n",
    "        if label_type not in summary_annotations[summ_uuid]:\n",
    "            summary_annotations[summ_uuid][label_type] = []\n",
    "\n",
    "        summary_annotations[summ_uuid][label_type].append((user_id, nonfact_sents))\n",
    "\n",
    "        label_annotations[user_id][label_type].append(summ_uuid)\n",
    "    #     print(summ_uuid, all_summ_uuids.index(summ_uuid))\n",
    "        sent_annotations[user_id][all_summ_uuids.index(summ_uuid)] = nonfact_sents\n",
    "    \n",
    "    return summary_annotations, label_annotations, sent_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b2062-d1f5-45f3-b66a-6b521bc22e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3cc85512-7468-4e5b-98ad-152c97fba026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_annotator_matrix_label(label_annotations):\n",
    "    all_ann_ids = sorted(list(label_annotations.keys()), key = len)\n",
    "    ann_matrix = {}\n",
    "    ann_matrix['annotators'] = all_ann_ids\n",
    "    for ann_id in all_ann_ids:\n",
    "        if ann_id not in ann_matrix:\n",
    "            ann_matrix[ann_id] = []\n",
    "        ann_id_len = len(label_annotations[ann_id]['non_factual']) \n",
    "        for idx, other_ann_id in enumerate(all_ann_ids):\n",
    "            num_factual_aggr = set(label_annotations[ann_id]['non_factual']).intersection(label_annotations[other_ann_id]['non_factual'])\n",
    "            # num_nonfactual_aggr = set(label_annotations[ann_id]['factual']).intersection(label_annotations[other_ann_id]['factual'])\n",
    "            ann_matrix[ann_id].append(len(num_factual_aggr)/ann_id_len)\n",
    "    return ann_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c9ff17b-dcb8-466c-81b5-2f6de27466c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_annotator_matrix_sent(sent_annotations):\n",
    "    all_ann_ids = sorted(list(label_annotations.keys()), key = len)\n",
    "    ann_matrix = {}\n",
    "    ann_matrix['annotators'] = all_ann_ids\n",
    "    for ann_id in all_ann_ids:\n",
    "        if ann_id not in ann_matrix:\n",
    "            ann_matrix[ann_id] = []\n",
    "            \n",
    "        # ann_sents = sent_annotations[ann_id]\n",
    "        \n",
    "        for other_ann_id in all_ann_ids:\n",
    "            other_ann_sent_counter = 0\n",
    "            # other_ann_sents = sent_annotations[ann_id]\n",
    "            # other_ann_sents = other_ann_sents.split('<new_annotation>')\n",
    "            other_ann_sent_counter = []\n",
    "            for idx, ann_sent in enumerate(sent_annotations[ann_id]):\n",
    "#                 print(idx)\n",
    "                other_ann_sent = sent_annotations[other_ann_id][idx]\n",
    "                ann_sents_idx = ann_sent.split('<new_annotation>')\n",
    "                other_ann_sents_idx = other_ann_sent.split('<new_annotation>')\n",
    "                \n",
    "                val = len(set(ann_sents_idx).intersection(other_ann_sents_idx))/len(ann_sents_idx)\n",
    "                val = round(val, 1)\n",
    "                # print(val)\n",
    "                # if ann_sent == other_ann_sent:\n",
    "                #     val = 1\n",
    "                # elif (ann_sent in other_ann_sent) or (other_ann_sent in ann_sent):\n",
    "                #     val = 0.5\n",
    "                # else:\n",
    "                #     val = 0\n",
    "                other_ann_sent_counter += [val]\n",
    "            ann_matrix[ann_id].append(np.mean(other_ann_sent_counter))\n",
    "    return ann_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cef79a25-ed80-4f13-bb97-1c849f19aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_annotations, label_annotations, sent_annotations = map_dicts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43b1326c-1016-426c-a58e-287fe282f088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1718f63-9947-4aef-b195-0c9ceb5d34d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators</th>\n",
       "      <th>ann_japq</th>\n",
       "      <th>ann_tpfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_japq</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann_tpfo</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotators  ann_japq  ann_tpfo\n",
       "0   ann_japq   1.00000  0.675676\n",
       "1   ann_tpfo   0.78125  1.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_matrix = compute_annotator_matrix_label(label_annotations)\n",
    "df_matrix = pd.DataFrame(ann_matrix)\n",
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6d9e0c0-8057-48b6-9416-7c1ef57c95e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators</th>\n",
       "      <th>ann_japq</th>\n",
       "      <th>ann_tpfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann_japq</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann_tpfo</td>\n",
       "      <td>0.749383</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotators  ann_japq  ann_tpfo\n",
       "0   ann_japq  1.000000  0.738272\n",
       "1   ann_tpfo  0.749383  1.000000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_matrix = compute_annotator_matrix_sent(sent_annotations)\n",
    "df_sent_matrix = pd.DataFrame(sent_matrix)\n",
    "df_sent_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "912371b6-424a-49e0-b8a2-67648cab0f08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_annotations['ann_krcnbm']['non_factual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109fdb8-68f2-4e75-8070-65f1bad5300a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
