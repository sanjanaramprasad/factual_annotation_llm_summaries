{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35eda160-16b5-4c51-b6e1-86fbeb0eefd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import string \n",
    "import re\n",
    "\n",
    "import json \n",
    "\n",
    "import pandas as pd \n",
    "import sqlite3\n",
    "import spacy\n",
    "import numpy as np\n",
    "from rouge import Rouge \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46563dc2-97d1-4b1f-b780-ebad2add5cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_path = '/home/ramprasad.sa/factual_annotation_llm_summaries/annotations'\n",
    "def read_files(task):\n",
    "    df_errors = pd.read_csv(f'{annotations_path}/{task}_annotations_scores.csv')\n",
    "    df_aggreg = pd.read_csv(f'{annotations_path}/{task}_annotations.csv')\n",
    "    return df_aggreg, df_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4e94850-d517-4171-83cf-0a25039b0e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def agreement_label(df):\n",
    "    ann1_summ_labels = []\n",
    "    ann2_summ_labels = []\n",
    "    for summid in list(set(df['summary_uuid'])):\n",
    "        df_summ = df[df['summary_uuid'] == summid]\n",
    "        ann1_label = list(set(df_summ['label_type_ann1']))\n",
    "        ann2_label = list(set(df_summ['label_type_ann2']))\n",
    "        assert (len(ann1_label) == 1 & len(ann2_label) == 1)\n",
    "        ann1_label = 1 if ann1_label[0] == 'factual' else 0\n",
    "        ann2_label = 1 if ann2_label[0] == 'factual' else 0\n",
    "        ann1_summ_labels += [ann1_label]\n",
    "        ann2_summ_labels += [ann2_label]\n",
    "        \n",
    "    assert len(ann1_summ_labels) == len(ann2_summ_labels)\n",
    "    agreed_ann = [each for idx, each in enumerate(ann1_summ_labels) if each == ann2_summ_labels[idx]]\n",
    "    agreement_score = len(agreed_ann)/len(ann1_summ_labels)\n",
    "    cohenk_score = cohen_kappa_score(ann1_summ_labels, ann2_summ_labels)\n",
    "    return agreement_score, cohenk_score\n",
    "    \n",
    "def agreement_sent(df):\n",
    "    ann1_summ_sent_labels = []\n",
    "    ann2_summ_sent_labels = []\n",
    "    \n",
    "    for summ in list(set(df['summary'].values)):\n",
    "        summ_sents = list(nlp(summ).sents)\n",
    "        for sent in summ_sents:\n",
    "            sent = sent.text\n",
    "            \n",
    "            if sent not in list(df['nonfactual_sentence'].values):\n",
    "                ann1_summ_sent_labels += [0]\n",
    "                ann2_summ_sent_labels += [0]\n",
    "            else:\n",
    "                \n",
    "                df_summ_sent = df[df['nonfactual_sentence'] == sent]\n",
    "                \n",
    "                ann1_label = list(df_summ_sent['inaccuracy_severity_ann1'].values)\n",
    "                # print(list(set(ann1_label)))\n",
    "                ann1_summ_sent_labels += [1 if type(each) is str else 0 for each in ann1_label]\n",
    "                \n",
    "                ann2_label = list(df_summ_sent['inaccuracy_severity_ann2'].values)\n",
    "                ann2_summ_sent_labels += [1 if type(each) is str else 0 for each in ann2_label]\n",
    "    \n",
    "    assert (len(ann1_summ_sent_labels) == len(ann2_summ_sent_labels))\n",
    "    agreed_ann = [each \n",
    "                  for idx, each in enumerate(ann1_summ_sent_labels)\n",
    "                      if each == ann2_summ_sent_labels[idx]]\n",
    "    agreement_score = len(agreed_ann)/len(ann1_summ_sent_labels)\n",
    "    cohenk_score = cohen_kappa_score(ann1_summ_sent_labels, ann2_summ_sent_labels)\n",
    "    # print(\n",
    "    return agreement_score, cohenk_score\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "def agreement_categ(df):\n",
    "    categ_map = {None: 0,\n",
    "                 'intrinsic': 1,\n",
    "                 'extrinsic': 2,\n",
    "                 'other': 3}\n",
    "    ann1_summ_sent_categ = []\n",
    "    ann2_summ_sent_categ = []\n",
    "\n",
    "    for summ in list(set(df['summary'].values)):\n",
    "        summ_sents = list(nlp(summ).sents)\n",
    "        for sent in summ_sents:\n",
    "            sent = sent.text\n",
    "            if sent not in list(df['nonfactual_sentence'].values):\n",
    "                ann1_summ_sent_categ += [0]\n",
    "                ann2_summ_sent_categ += [0]\n",
    "            else:\n",
    "                df_summ_sent = df[df['nonfactual_sentence'] == sent]\n",
    "\n",
    "                ann1_categs = list(df_summ_sent['error_type_ann1'].values)\n",
    "                ann1_categs = [each if type(each) is str else None for each in ann1_categs]\n",
    "\n",
    "                ann2_categs = list(df_summ_sent['error_type_ann2'].values)\n",
    "                ann2_categs = [each if type(each) is str else None for each in ann2_categs]\n",
    "\n",
    "                ann1_summ_sent_categ += [categ_map[each] for each in ann1_categs]\n",
    "                ann2_summ_sent_categ += [categ_map[each] for each in ann2_categs]\n",
    "\n",
    "    assert(len(ann1_summ_sent_categ) == len(ann2_summ_sent_categ))\n",
    "    agreed_ann = [idx \n",
    "                      for idx, each in enumerate(ann1_summ_sent_categ) \n",
    "                          if each == ann2_summ_sent_categ[idx]]\n",
    "    agreement_score = len(agreed_ann)/len(ann2_summ_sent_categ)\n",
    "    cohenk_score = cohen_kappa_score(ann1_summ_sent_categ, ann2_summ_sent_categ)   \n",
    "    return agreement_score, cohenk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb9c0c69-02a4-4800-8510-e119c8a66507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_errors_news, df_aggr_news = read_files('news')\n",
    "df_errors_billsum, df_aggr_billsum= read_files('billsum')\n",
    "df_errors_pubmed, df_aggr_pubmed= read_files('pubmed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0af968f4-02a3-4740-bea8-caaef287fed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** NEWS*****\n",
      "Sent Agreement (Agg/Cohen) (0.9169139465875371, 0.6547636470071712)\n",
      "Categ Agreement (Agg/Cohen) (0.8635014836795252, 0.45576463979778115)\n",
      "Summary Agreement (Agg/Cohen) (0.8, 0.5612110574813515)\n"
     ]
    }
   ],
   "source": [
    "print('***** NEWS*****')\n",
    "\n",
    "print('Sent Agreement (Agg/Cohen)', agreement_sent(df_errors_news))\n",
    "print('Categ Agreement (Agg/Cohen)', agreement_categ(df_errors_news))\n",
    "print('Summary Agreement (Agg/Cohen)', agreement_label(df_errors_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c257edd-82ed-47a1-a679-ee7810991c48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Billsum*****\n",
      "Sent Agreement (Agg/Cohen) (0.7857142857142857, 0.17260787992495308)\n",
      "Categ Agreement (Agg/Cohen) (0.7755102040816326, 0.17037923810338196)\n",
      "Summary Agreement (Agg/Cohen) (0.72, 0.3738819320214669)\n"
     ]
    }
   ],
   "source": [
    "print('***** Billsum*****')\n",
    "\n",
    "print('Sent Agreement (Agg/Cohen)', agreement_sent(df_errors_billsum))\n",
    "print('Categ Agreement (Agg/Cohen)', agreement_categ(df_errors_billsum))\n",
    "print('Summary Agreement (Agg/Cohen)', agreement_label(df_errors_billsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a533fe1d-adb1-4ad4-88ed-69b702f45919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Pubmed *****\n",
      "Sent Agreement (Agg/Cohen) (0.9273182957393483, 0.10545032856590641)\n",
      "Categ Agreement (Agg/Cohen) (0.9223057644110275, 0.052256532066508155)\n",
      "Summary Agreement (Agg/Cohen) (0.85, 0.1573033707865169)\n"
     ]
    }
   ],
   "source": [
    "print('***** Pubmed *****')\n",
    "\n",
    "print('Sent Agreement (Agg/Cohen)', agreement_sent(df_errors_pubmed))\n",
    "print('Categ Agreement (Agg/Cohen)', agreement_categ(df_errors_pubmed))\n",
    "print('Summary Agreement (Agg/Cohen)', agreement_label(df_errors_pubmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0abb0b81-afd7-4209-852a-c18a6d54f8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7755102040816326, 0.17037923810338196)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement_categ(df_errors_billsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb511b2-34df-474a-842c-d8d251751a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
