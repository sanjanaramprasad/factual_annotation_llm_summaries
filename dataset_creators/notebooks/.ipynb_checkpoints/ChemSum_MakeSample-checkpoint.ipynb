{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64ce713-b1c0-4a7b-b19d-475c5168e188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import dataset_creators.config as config\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82316c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prompt_token_limits(article, instructions, tokenizer, token_limit):\n",
    "    counter = 0\n",
    "    for key, instruction in instructions.items():\n",
    "        prompt = f'Article: {article}\\n{instruction}'\n",
    "        prompt_len = len(tokenizer.encode(prompt))\n",
    "        if prompt_len < token_limit:\n",
    "            counter += 1 \n",
    "    return counter \n",
    "\n",
    "def get_shortlisted_data(articles, reference_summaries, ids = [], token_limit = 4096, dataset = 'xsum'):\n",
    "    \n",
    "    flan_tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "    flan_instructions = config.instructions[f'{dataset}_flant5']\n",
    "    \n",
    "    gpt_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    gpt_instructions = config.instructions[f'{dataset}_gpt3']\n",
    "    \n",
    "    shortlisted_articles = []\n",
    "    shortlisted_reference_summaries = []\n",
    "    \n",
    "    shortlisted_ids = []\n",
    "    \n",
    "    for idx, article in enumerate(articles):\n",
    "        add_article = 0 \n",
    "        \n",
    "        flan_counter = check_prompt_token_limits(article, flan_instructions, flan_tokenizer, token_limit)\n",
    "        add_article += flan_counter\n",
    "        \n",
    "        gpt_counter = check_prompt_token_limits(article, gpt_instructions, gpt_tokenizer, token_limit)\n",
    "        add_article += gpt_counter\n",
    "        \n",
    "\n",
    "        if add_article == 4:\n",
    "            shortlisted_articles.append(article)\n",
    "            shortlisted_reference_summaries.append(reference_summaries[idx])\n",
    "            \n",
    "            if not ids:\n",
    "                article_id = str(uuid.uuid4())\n",
    "            else:\n",
    "                article_id = ids[idx]\n",
    "            \n",
    "            shortlisted_ids.append(article_id)\n",
    "            \n",
    "    return shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids\n",
    "\n",
    "def preprocess_html_tags(article):\n",
    "    CLEANR = re.compile('<.*?>') \n",
    "    article = re.sub(CLEANR, '', article)\n",
    "    return article\n",
    "\n",
    "def make_sample_chemsum(data_path, token_limit = 4096):\n",
    "    dataset = load_dataset(\"griffin/ChemSum\", split = 'test', cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')\n",
    "    articles = dataset['sections']\n",
    "    articles = [preprocess_html_tags(each) for each in articles]\n",
    "    reference_summaries = dataset['abstract']\n",
    "    ids = dataset['uuid']\n",
    "    \n",
    "    \n",
    "    shortlisted_data = {'article': [], 'reference_summary': [], 'id': [], 'origin': []}\n",
    "    \n",
    "    shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids = get_shortlisted_data(articles, reference_summaries, ids, dataset = 'chemsum' )\n",
    "    shortlisted_data['article'] += shortlisted_articles\n",
    "    shortlisted_data['reference_summary'] += shortlisted_reference_summaries\n",
    "    shortlisted_data['id'] += shortlisted_ids\n",
    "    shortlisted_data['origin'] += ['chemsum'] * len(shortlisted_ids)\n",
    "            \n",
    "    isExist = os.path.exists(data_path)\n",
    "    if not isExist:\n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    df = pd.DataFrame(shortlisted_data)\n",
    "    df.to_csv(f'{data_path}/test_sample.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24f9dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/scratch/ramprasad.sa/huggingface_datasets/griffin___parquet/griffin--ChemSum-f0741275208cf814/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'chemsum_flan_t5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_sample_chemsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ramprasad.sa/factual_annotation_llm_summaries/datasets/chemsum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m, in \u001b[0;36mmake_sample_chemsum\u001b[0;34m(data_path, token_limit)\u001b[0m\n\u001b[1;32m     56\u001b[0m ids \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m shortlisted_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference_summary\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m---> 61\u001b[0m shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_shortlisted_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchemsum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m shortlisted_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m shortlisted_articles\n\u001b[1;32m     63\u001b[0m shortlisted_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference_summary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m shortlisted_reference_summaries\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mget_shortlisted_data\u001b[0;34m(articles, reference_summaries, ids, token_limit, dataset)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_shortlisted_data\u001b[39m(articles, reference_summaries, ids \u001b[38;5;241m=\u001b[39m [], token_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m, dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxsum\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     12\u001b[0m     flan_tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-xl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     flan_instructions \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstructions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_flan_t5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     gpt_tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mencoding_for_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     gpt_instructions \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minstructions[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_gpt3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chemsum_flan_t5'"
     ]
    }
   ],
   "source": [
    "make_sample_chemsum('/home/ramprasad.sa/factual_annotation_llm_summaries/datasets/chemsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea877fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bi-mediated_allylation_of_aldehydes_in_[bmim][br]:_a_mechanistic_investigation'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb21f4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_gpt3': {'Generic_summary': 'Summarize the above article',\n",
       "  'Faithful_summary': 'Summarize the above article such that all the information in the summary is supported by the article'},\n",
       " 'news_flan_t5': {'Generic_summary': 'Summarize the above article',\n",
       "  'Faithful_summary': 'Summarize the above article such that all the information in the summary is supported by the article'},\n",
       " 'pubmed_gpt3': {'Generic_summary': 'Summarize the above article',\n",
       "  'Faithful_summary': 'Summarize the above article such that all the information in the summary is supported by the article'},\n",
       " 'pubmed_flant5': {'Generic_summary': 'Summarize the above article',\n",
       "  'Faithful_summary': 'Summarize the above article such that all the information in the summary is supported by the article'},\n",
       " 'chemsum_gpt3': {'Generic_summary': 'Summarize the above article',\n",
       "  'Faithful_summary': 'Summarize the above article such that all the information in the summary is supported by the article'},\n",
       " 'chemsum_flant5': {'Generic_summary': 'Summarize the above article',\n",
       "  'Faithful_summary': 'Summarize the above article such that all the information in the summary is supported by the article'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900de757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
