{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59064a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00152eb0363d4dc4a7fa835ec385c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset scitldr/FullText (download: 46.14 MiB, generated: 95.46 MiB, post-processed: Unknown size, total: 141.60 MiB) to /scratch/ramprasad.sa/huggingface_datasets/Blaise-g___parquet/Blaise-g--scitldr-0e01d2d9de8032a7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6591ebe45ea4bfab9174fae5a4a6941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b4b0c831174c6b9b062b588d3c4b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/29.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7844f9a6792b43e4ba7bc8ace614a64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf1e3504b69489b89229cf538a85939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f23921a9a534e78add8a21f6ca4e638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/618 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /scratch/ramprasad.sa/huggingface_datasets/Blaise-g___parquet/Blaise-g--scitldr-0e01d2d9de8032a7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4b1183964a402e9ee84a71d8115a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Blaise-g/scitldr\", cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93547828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import dataset_creators.config as config\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aad1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prompt_token_limits(article, instructions, tokenizer, token_limit):\n",
    "    counter = 0\n",
    "    for key, instruction in instructions.items():\n",
    "        prompt = f'Article: {article}\\n{instruction}'\n",
    "        prompt_len = len(tokenizer.encode(prompt))\n",
    "        if prompt_len < token_limit:\n",
    "            counter += 1 \n",
    "    return counter \n",
    "\n",
    "def get_shortlisted_data(articles, reference_summaries, ids = [], token_limit = 4096, dataset = 'xsum'):\n",
    "    \n",
    "    flan_tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "    flan_instructions = config.instructions[f'{dataset}_flant5']\n",
    "    \n",
    "    gpt_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    gpt_instructions = config.instructions[f'{dataset}_gpt3']\n",
    "    \n",
    "    shortlisted_articles = []\n",
    "    shortlisted_reference_summaries = []\n",
    "    \n",
    "    shortlisted_ids = []\n",
    "    \n",
    "    for idx, article in enumerate(articles):\n",
    "        add_article = 0 \n",
    "        \n",
    "        flan_counter = check_prompt_token_limits(article, flan_instructions, flan_tokenizer, token_limit)\n",
    "        add_article += flan_counter\n",
    "        \n",
    "        gpt_counter = check_prompt_token_limits(article, gpt_instructions, gpt_tokenizer, token_limit)\n",
    "        add_article += gpt_counter\n",
    "        \n",
    "\n",
    "        if add_article == 4:\n",
    "            shortlisted_articles.append(article)\n",
    "            shortlisted_reference_summaries.append(reference_summaries[idx])\n",
    "            \n",
    "            if not ids:\n",
    "                article_id = str(uuid.uuid4())\n",
    "            else:\n",
    "                article_id = ids[idx]\n",
    "            \n",
    "            shortlisted_ids.append(article_id)\n",
    "            \n",
    "    return shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids\n",
    "\n",
    "def preprocess_html_tags(article):\n",
    "    CLEANR = re.compile('<.*?>') \n",
    "    article = re.sub(CLEANR, '', article)\n",
    "    return article\n",
    "\n",
    "def make_sample_scitldr(data_path, token_limit = 4096):\n",
    "    dataset = load_dataset(\"allenai/scitldr\", split = 'test', cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')\n",
    "    articles = dataset['source']\n",
    "#     articles = [preprocess_html_tags(each) for each in articles]\n",
    "    articles = ['\\n'.join(each) for each in articles]\n",
    "    reference_summaries = dataset['target']\n",
    "    ids = dataset['paper_id']\n",
    "    \n",
    "    \n",
    "    shortlisted_data = {'article': [], 'reference_summary': [], 'id': [], 'origin': []}\n",
    "    \n",
    "    shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids = get_shortlisted_data(articles, reference_summaries, ids, dataset = 'chemsum' )\n",
    "    shortlisted_data['article'] += shortlisted_articles\n",
    "    shortlisted_data['reference_summary'] += shortlisted_reference_summaries\n",
    "    shortlisted_data['id'] += shortlisted_ids\n",
    "    shortlisted_data['origin'] += ['scitldr'] * len(shortlisted_ids)\n",
    "            \n",
    "    isExist = os.path.exists(data_path)\n",
    "    if not isExist:\n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    df = pd.DataFrame(shortlisted_data)\n",
    "    df.to_csv(f'{data_path}/test_sample.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eabfa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/scratch/ramprasad.sa/huggingface_datasets/Blaise-g___parquet/Blaise-g--scitldr-0e01d2d9de8032a7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8739 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>id</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The variational autoencoder (VAE) is a popular...</td>\n",
       "      <td>To address posterior collapse in VAEs, we prop...</td>\n",
       "      <td>rylDfnCqF7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generative models have been successfully appli...</td>\n",
       "      <td>The paper uses Variational Auto-Encoding and n...</td>\n",
       "      <td>HJgOl3AqY7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quality of the features used in visual rec...</td>\n",
       "      <td>A simple fast method for extracting visual fea...</td>\n",
       "      <td>SyGT_6yCZ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Humans are capable of attributing latent menta...</td>\n",
       "      <td>We proposed a novel probabilisitic recursive r...</td>\n",
       "      <td>rkl6As0cF7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deep learning has found numerous applications ...</td>\n",
       "      <td>We introduce a transparent middleware for neur...</td>\n",
       "      <td>rkf5hnNDj7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Humans possess an ability to abstractly reason...</td>\n",
       "      <td>We introduce Recurrent Relational Networks, a ...</td>\n",
       "      <td>SkJKHMW0Z</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Modern Convolutional Neural Networks (CNNs) ar...</td>\n",
       "      <td>In this paper, we develop fast retraining-free...</td>\n",
       "      <td>rkz1YD0vjm</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Backprop is the primary learning algorithm use...</td>\n",
       "      <td>We ignore non-linearities and do not compute g...</td>\n",
       "      <td>ByfPDyrYim</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep network compression seeks to reduce the n...</td>\n",
       "      <td>We seek to understand learned representations ...</td>\n",
       "      <td>HJWpQCa7z</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This paper introduces HybridNet, a hybrid neur...</td>\n",
       "      <td>It is a hybrid neural architecture to speed-up...</td>\n",
       "      <td>rJoXrxZAZ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The growing interest to implement Deep Neural ...</td>\n",
       "      <td>Compressing trained DNN models by minimizing t...</td>\n",
       "      <td>By0ANxbRW</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural architecture search (NAS) has a great i...</td>\n",
       "      <td>Proxy-less neural architecture search for dire...</td>\n",
       "      <td>HylVB3AqYm</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In this work, we exploited different strategie...</td>\n",
       "      <td>We evaluate the effectiveness of having auxili...</td>\n",
       "      <td>ryeHw1vjiQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Generalization from limited examples, usually ...</td>\n",
       "      <td>We proposed Projective Subspace Networks for f...</td>\n",
       "      <td>rkzfuiA9F7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Text editing on mobile devices can be a tediou...</td>\n",
       "      <td>In this work, we present Gedit, a system of on...</td>\n",
       "      <td>CZ938F7zVF</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The use of AR in an industrial context could h...</td>\n",
       "      <td>This paper describe a 3D authoring tool for pr...</td>\n",
       "      <td>1qdNTwXpgE</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data-parallel neural network training is netwo...</td>\n",
       "      <td>We improve gradient dropping (a technique of o...</td>\n",
       "      <td>BkeSusCcYm</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Humans acquire complex skills by exploiting pr...</td>\n",
       "      <td>Transition policies enable agents to compose c...</td>\n",
       "      <td>rygrBhC5tQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The current dominant paradigm for imitation le...</td>\n",
       "      <td>Agents can learn to imitate solely visual demo...</td>\n",
       "      <td>BkisuzWRW</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Word embeddings are widely used in machine lea...</td>\n",
       "      <td>Researchers exploring natural language process...</td>\n",
       "      <td>H1glKiCqtm</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>In the past few years, various advancements ha...</td>\n",
       "      <td>Generating text using sentence embeddings from...</td>\n",
       "      <td>SkGMOi05FQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Generative Adversarial Networks (GANs) are pow...</td>\n",
       "      <td>This paper proposes a new Generative Adversari...</td>\n",
       "      <td>HyMuaiAqY7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Modern generative models are usually designed ...</td>\n",
       "      <td>A framework for training autoencoder-based gen...</td>\n",
       "      <td>rkxkr8UKuN</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Many imaging tasks require global information ...</td>\n",
       "      <td>Presents new architecture which leverages info...</td>\n",
       "      <td>BJgFcj0qKX</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>We explore ways of incorporating bilingual dic...</td>\n",
       "      <td>We use bilingual dictionaries for data augment...</td>\n",
       "      <td>B1ecYsqSuN</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The high dimensionality of hyperspectral imagi...</td>\n",
       "      <td>We applied deep learning techniques to hypersp...</td>\n",
       "      <td>HkanP0lRW</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Generative adversarial networks (GANs) are a p...</td>\n",
       "      <td>A noval GAN framework that utilizes transforma...</td>\n",
       "      <td>ry0WOxbRZ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>We propose a method for learning the dependenc...</td>\n",
       "      <td>We propose a method for learning latent depend...</td>\n",
       "      <td>SJgsCjCqt7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>This research paper describes a simplistic arc...</td>\n",
       "      <td>Tied weights auto-encoder with abs function as...</td>\n",
       "      <td>rkhxwltab</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Verifying a person's identity based on their ...</td>\n",
       "      <td>Speaker verificaiton performance can be signif...</td>\n",
       "      <td>Byx4xH3is7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Learning disentangling representations of the ...</td>\n",
       "      <td>Minimising the synergistic mutual information ...</td>\n",
       "      <td>Skl3M20qYQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Residual and skip connections play an importa...</td>\n",
       "      <td>We show how using skip connections can make sp...</td>\n",
       "      <td>rkzeXBDos7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Deep Learning NLP domain lacks procedures for ...</td>\n",
       "      <td>We propose a model agnostic approach to valida...</td>\n",
       "      <td>SJlgRqjssQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>As neural networks grow deeper and wider, lear...</td>\n",
       "      <td>We learn deep networks of hard-threshold units...</td>\n",
       "      <td>B1Lc-Gb0Z</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>While self-organizing principles have motivate...</td>\n",
       "      <td>integration of self-organization and supervise...</td>\n",
       "      <td>BJ8lbVAfz</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A central challenge in reinforcement learning ...</td>\n",
       "      <td>Training agents with goal-policy information b...</td>\n",
       "      <td>rJg8yhAqKm</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              article   \n",
       "0   The variational autoencoder (VAE) is a popular...  \\\n",
       "1   Generative models have been successfully appli...   \n",
       "2   The quality of the features used in visual rec...   \n",
       "3   Humans are capable of attributing latent menta...   \n",
       "4   Deep learning has found numerous applications ...   \n",
       "5   Humans possess an ability to abstractly reason...   \n",
       "6   Modern Convolutional Neural Networks (CNNs) ar...   \n",
       "7   Backprop is the primary learning algorithm use...   \n",
       "8   Deep network compression seeks to reduce the n...   \n",
       "9   This paper introduces HybridNet, a hybrid neur...   \n",
       "10  The growing interest to implement Deep Neural ...   \n",
       "11  Neural architecture search (NAS) has a great i...   \n",
       "12  In this work, we exploited different strategie...   \n",
       "13  Generalization from limited examples, usually ...   \n",
       "14  Text editing on mobile devices can be a tediou...   \n",
       "15  The use of AR in an industrial context could h...   \n",
       "16  Data-parallel neural network training is netwo...   \n",
       "17  Humans acquire complex skills by exploiting pr...   \n",
       "18  The current dominant paradigm for imitation le...   \n",
       "19  Word embeddings are widely used in machine lea...   \n",
       "20  In the past few years, various advancements ha...   \n",
       "21  Generative Adversarial Networks (GANs) are pow...   \n",
       "22  Modern generative models are usually designed ...   \n",
       "23  Many imaging tasks require global information ...   \n",
       "24  We explore ways of incorporating bilingual dic...   \n",
       "25  The high dimensionality of hyperspectral imagi...   \n",
       "26  Generative adversarial networks (GANs) are a p...   \n",
       "27  We propose a method for learning the dependenc...   \n",
       "28  This research paper describes a simplistic arc...   \n",
       "29   Verifying a person's identity based on their ...   \n",
       "30  Learning disentangling representations of the ...   \n",
       "31   Residual and skip connections play an importa...   \n",
       "32  Deep Learning NLP domain lacks procedures for ...   \n",
       "33  As neural networks grow deeper and wider, lear...   \n",
       "34  While self-organizing principles have motivate...   \n",
       "35  A central challenge in reinforcement learning ...   \n",
       "\n",
       "                                    reference_summary          id   origin  \n",
       "0   To address posterior collapse in VAEs, we prop...  rylDfnCqF7  scitldr  \n",
       "1   The paper uses Variational Auto-Encoding and n...  HJgOl3AqY7  scitldr  \n",
       "2   A simple fast method for extracting visual fea...   SyGT_6yCZ  scitldr  \n",
       "3   We proposed a novel probabilisitic recursive r...  rkl6As0cF7  scitldr  \n",
       "4   We introduce a transparent middleware for neur...  rkf5hnNDj7  scitldr  \n",
       "5   We introduce Recurrent Relational Networks, a ...   SkJKHMW0Z  scitldr  \n",
       "6   In this paper, we develop fast retraining-free...  rkz1YD0vjm  scitldr  \n",
       "7   We ignore non-linearities and do not compute g...  ByfPDyrYim  scitldr  \n",
       "8   We seek to understand learned representations ...   HJWpQCa7z  scitldr  \n",
       "9   It is a hybrid neural architecture to speed-up...   rJoXrxZAZ  scitldr  \n",
       "10  Compressing trained DNN models by minimizing t...   By0ANxbRW  scitldr  \n",
       "11  Proxy-less neural architecture search for dire...  HylVB3AqYm  scitldr  \n",
       "12  We evaluate the effectiveness of having auxili...  ryeHw1vjiQ  scitldr  \n",
       "13  We proposed Projective Subspace Networks for f...  rkzfuiA9F7  scitldr  \n",
       "14  In this work, we present Gedit, a system of on...  CZ938F7zVF  scitldr  \n",
       "15  This paper describe a 3D authoring tool for pr...  1qdNTwXpgE  scitldr  \n",
       "16  We improve gradient dropping (a technique of o...  BkeSusCcYm  scitldr  \n",
       "17  Transition policies enable agents to compose c...  rygrBhC5tQ  scitldr  \n",
       "18  Agents can learn to imitate solely visual demo...   BkisuzWRW  scitldr  \n",
       "19  Researchers exploring natural language process...  H1glKiCqtm  scitldr  \n",
       "20  Generating text using sentence embeddings from...  SkGMOi05FQ  scitldr  \n",
       "21  This paper proposes a new Generative Adversari...  HyMuaiAqY7  scitldr  \n",
       "22  A framework for training autoencoder-based gen...  rkxkr8UKuN  scitldr  \n",
       "23  Presents new architecture which leverages info...  BJgFcj0qKX  scitldr  \n",
       "24  We use bilingual dictionaries for data augment...  B1ecYsqSuN  scitldr  \n",
       "25  We applied deep learning techniques to hypersp...   HkanP0lRW  scitldr  \n",
       "26  A noval GAN framework that utilizes transforma...   ry0WOxbRZ  scitldr  \n",
       "27  We propose a method for learning latent depend...  SJgsCjCqt7  scitldr  \n",
       "28  Tied weights auto-encoder with abs function as...   rkhxwltab  scitldr  \n",
       "29  Speaker verificaiton performance can be signif...  Byx4xH3is7  scitldr  \n",
       "30  Minimising the synergistic mutual information ...  Skl3M20qYQ  scitldr  \n",
       "31  We show how using skip connections can make sp...  rkzeXBDos7  scitldr  \n",
       "32  We propose a model agnostic approach to valida...  SJlgRqjssQ  scitldr  \n",
       "33  We learn deep networks of hard-threshold units...   B1Lc-Gb0Z  scitldr  \n",
       "34  integration of self-organization and supervise...   BJ8lbVAfz  scitldr  \n",
       "35  Training agents with goal-policy information b...  rJg8yhAqKm  scitldr  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sample_scitldr('/home/ramprasad.sa/factual_annotation_llm_summaries/datasets/scitldr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46bd3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: scitldr/Abstract\n",
      "Found cached dataset scitldr (/scratch/ramprasad.sa/huggingface_datasets/allenai___scitldr/Abstract/0.0.0/79e0fa75961392034484808cfcc8f37deb15ceda153b798c92d9f621d1042fef)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = dataset = load_dataset(\"allenai/scitldr\", split = 'test', cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e2cf781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental class learning involves sequentially learning classes in bursts of examples from the same class.\n",
      "This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting.\n",
      "Arguably, the best method for incremental class learning is iCaRL, but it requires storing  training examples for each class, making it challenging to scale.\n",
      "Here, we propose FearNet for incremental class learning.\n",
      "FearNet is a generative model that does not store previous examples, making it memory efficient.\n",
      "FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex.\n",
      "Memory consolidation is inspired by mechanisms that occur during sleep.\n",
      "FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall.  \n",
      "FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(dataset['source'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bda28355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec8d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
