{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59064a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00152eb0363d4dc4a7fa835ec385c081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset scitldr/FullText (download: 46.14 MiB, generated: 95.46 MiB, post-processed: Unknown size, total: 141.60 MiB) to /scratch/ramprasad.sa/huggingface_datasets/Blaise-g___parquet/Blaise-g--scitldr-0e01d2d9de8032a7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6591ebe45ea4bfab9174fae5a4a6941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b4b0c831174c6b9b062b588d3c4b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/29.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7844f9a6792b43e4ba7bc8ace614a64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf1e3504b69489b89229cf538a85939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f23921a9a534e78add8a21f6ca4e638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/618 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /scratch/ramprasad.sa/huggingface_datasets/Blaise-g___parquet/Blaise-g--scitldr-0e01d2d9de8032a7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4b1183964a402e9ee84a71d8115a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Blaise-g/scitldr\", cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93547828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import dataset_creators.config as config\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5aad1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prompt_token_limits(article, instructions, tokenizer, token_limit):\n",
    "    counter = 0\n",
    "    for key, instruction in instructions.items():\n",
    "        prompt = f'Article: {article}\\n{instruction}'\n",
    "        prompt_len = len(tokenizer.encode(prompt))\n",
    "        if prompt_len < token_limit:\n",
    "            counter += 1 \n",
    "    return counter \n",
    "\n",
    "def get_shortlisted_data(articles, reference_summaries, ids = [], token_limit = 4096, dataset = 'xsum'):\n",
    "    \n",
    "    flan_tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "    flan_instructions = config.instructions[f'{dataset}_flant5']\n",
    "    \n",
    "    gpt_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    gpt_instructions = config.instructions[f'{dataset}_gpt3']\n",
    "    \n",
    "    shortlisted_articles = []\n",
    "    shortlisted_reference_summaries = []\n",
    "    \n",
    "    shortlisted_ids = []\n",
    "    \n",
    "    for idx, article in enumerate(articles):\n",
    "        add_article = 0 \n",
    "        \n",
    "        flan_counter = check_prompt_token_limits(article, flan_instructions, flan_tokenizer, token_limit)\n",
    "        add_article += flan_counter\n",
    "        \n",
    "        gpt_counter = check_prompt_token_limits(article, gpt_instructions, gpt_tokenizer, token_limit)\n",
    "        add_article += gpt_counter\n",
    "        \n",
    "\n",
    "        if add_article == 4:\n",
    "            shortlisted_articles.append(article)\n",
    "            shortlisted_reference_summaries.append(reference_summaries[idx])\n",
    "            \n",
    "            if not ids:\n",
    "                article_id = str(uuid.uuid4())\n",
    "            else:\n",
    "                article_id = ids[idx]\n",
    "            \n",
    "            shortlisted_ids.append(article_id)\n",
    "            \n",
    "    return shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids\n",
    "\n",
    "def preprocess_html_tags(article):\n",
    "    CLEANR = re.compile('<.*?>') \n",
    "    article = re.sub(CLEANR, '', article)\n",
    "    return article\n",
    "\n",
    "def make_sample_scitldr(data_path, token_limit = 4096):\n",
    "    dataset = load_dataset(\"allenai/scitldr\", split = 'test', cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')\n",
    "    articles = dataset['source']\n",
    "#     articles = [preprocess_html_tags(each) for each in articles]\n",
    "    articles = ['\\n'.join(each) for each in articles]\n",
    "    print(articles[0])\n",
    "    reference_summaries = dataset['target']\n",
    "    ids = dataset['paper_id']\n",
    "    \n",
    "    \n",
    "    shortlisted_data = {'article': [], 'reference_summary': [], 'id': [], 'origin': []}\n",
    "    \n",
    "    shortlisted_articles, shortlisted_reference_summaries, shortlisted_ids = get_shortlisted_data(articles, reference_summaries, ids, dataset = 'chemsum' )\n",
    "    shortlisted_data['article'] += shortlisted_articles\n",
    "    shortlisted_data['reference_summary'] += shortlisted_reference_summaries\n",
    "    shortlisted_data['id'] += shortlisted_ids\n",
    "    shortlisted_data['origin'] += ['scitldr'] * len(shortlisted_ids)\n",
    "            \n",
    "    isExist = os.path.exists(data_path)\n",
    "    if not isExist:\n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    df = pd.DataFrame(shortlisted_data)\n",
    "    df.to_csv(f'{data_path}/test_sample.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe9b3b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: scitldr/Abstract\n",
      "Found cached dataset scitldr (/scratch/ramprasad.sa/huggingface_datasets/allenai___scitldr/Abstract/0.0.0/79e0fa75961392034484808cfcc8f37deb15ceda153b798c92d9f621d1042fef)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental class learning involves sequentially learning classes in bursts of examples from the same class.\n",
      "This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting.\n",
      "Arguably, the best method for incremental class learning is iCaRL, but it requires storing  training examples for each class, making it challenging to scale.\n",
      "Here, we propose FearNet for incremental class learning.\n",
      "FearNet is a generative model that does not store previous examples, making it memory efficient.\n",
      "FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex.\n",
      "Memory consolidation is inspired by mechanisms that occur during sleep.\n",
      "FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall.  \n",
      "FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>id</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Incremental class learning involves sequential...</td>\n",
       "      <td>[FearNet is a memory efficient neural-network,...</td>\n",
       "      <td>SJ1Xmf-Rb</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-view learning can provide self-supervisi...</td>\n",
       "      <td>[Multi-view learning improves unsupervised sen...</td>\n",
       "      <td>S1xzyhR9Y7</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We show how discrete objects can be learnt in ...</td>\n",
       "      <td>[We show how discrete objects can be learnt in...</td>\n",
       "      <td>HJDUjKeA-</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most recent gains in visual recognition have o...</td>\n",
       "      <td>[A large-scale dataset for training attention ...</td>\n",
       "      <td>BJgLg3R9KQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In recent years, deep neural networks have dem...</td>\n",
       "      <td>[We proposed a time-efficient defense method a...</td>\n",
       "      <td>BklpOo09tQ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Generative adversarial training can be general...</td>\n",
       "      <td>[This paper studies the discrimination and gen...</td>\n",
       "      <td>Hk9Xc_lR-</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Normalization layers are a staple in state-of-...</td>\n",
       "      <td>[All you need to train deep residual networks ...</td>\n",
       "      <td>H1gsz30cKX</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Designing a metric manually for unsupervised s...</td>\n",
       "      <td>[This paper aims to learn a better metric for ...</td>\n",
       "      <td>r1kP7vlRb</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>One of the most successful techniques in gener...</td>\n",
       "      <td>[Decompose the task of learning a generative m...</td>\n",
       "      <td>rJTGkKxAZ</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Visual grounding of language is an active rese...</td>\n",
       "      <td>[We propose a joint model to incorporate visua...</td>\n",
       "      <td>BJe8niAqKX</td>\n",
       "      <td>scitldr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article   \n",
       "0    Incremental class learning involves sequential...  \\\n",
       "1    Multi-view learning can provide self-supervisi...   \n",
       "2    We show how discrete objects can be learnt in ...   \n",
       "3    Most recent gains in visual recognition have o...   \n",
       "4    In recent years, deep neural networks have dem...   \n",
       "..                                                 ...   \n",
       "613  Generative adversarial training can be general...   \n",
       "614  Normalization layers are a staple in state-of-...   \n",
       "615  Designing a metric manually for unsupervised s...   \n",
       "616  One of the most successful techniques in gener...   \n",
       "617  Visual grounding of language is an active rese...   \n",
       "\n",
       "                                     reference_summary          id   origin  \n",
       "0    [FearNet is a memory efficient neural-network,...   SJ1Xmf-Rb  scitldr  \n",
       "1    [Multi-view learning improves unsupervised sen...  S1xzyhR9Y7  scitldr  \n",
       "2    [We show how discrete objects can be learnt in...   HJDUjKeA-  scitldr  \n",
       "3    [A large-scale dataset for training attention ...  BJgLg3R9KQ  scitldr  \n",
       "4    [We proposed a time-efficient defense method a...  BklpOo09tQ  scitldr  \n",
       "..                                                 ...         ...      ...  \n",
       "613  [This paper studies the discrimination and gen...   Hk9Xc_lR-  scitldr  \n",
       "614  [All you need to train deep residual networks ...  H1gsz30cKX  scitldr  \n",
       "615  [This paper aims to learn a better metric for ...   r1kP7vlRb  scitldr  \n",
       "616  [Decompose the task of learning a generative m...   rJTGkKxAZ  scitldr  \n",
       "617  [We propose a joint model to incorporate visua...  BJe8niAqKX  scitldr  \n",
       "\n",
       "[618 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sample_scitldr('/home/ramprasad.sa/factual_annotation_llm_summaries/datasets/scitldr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46bd3dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: scitldr/Abstract\n",
      "Found cached dataset scitldr (/scratch/ramprasad.sa/huggingface_datasets/allenai___scitldr/Abstract/0.0.0/79e0fa75961392034484808cfcc8f37deb15ceda153b798c92d9f621d1042fef)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = dataset = load_dataset(\"allenai/scitldr\", split = 'test', cache_dir = '/scratch/ramprasad.sa/huggingface_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e2cf781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental class learning involves sequentially learning classes in bursts of examples from the same class.\n",
      "This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting.\n",
      "Arguably, the best method for incremental class learning is iCaRL, but it requires storing  training examples for each class, making it challenging to scale.\n",
      "Here, we propose FearNet for incremental class learning.\n",
      "FearNet is a generative model that does not store previous examples, making it memory efficient.\n",
      "FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex.\n",
      "Memory consolidation is inspired by mechanisms that occur during sleep.\n",
      "FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall.  \n",
      "FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(dataset['source'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb348fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56d3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
